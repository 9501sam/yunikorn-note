# 0520
動機：找到資源不夠，就不接受請求的條件式

https://github.com/apache/yunikorn-core/blob/a590b7d0059cc875bc9ba5c81451a3db14c54326/pkg/scheduler/context.go#L484
```go
func (cc *ClusterContext) handleRMUpdateApplicationEvent(event *rmevent.RMUpdateApplicationEvent) {
	request := event.Request
	if len(request.New) == 0 && len(request.Remove) == 0 {
		return
	}
	acceptedApps := make([]*si.AcceptedApplication, 0)
	rejectedApps := make([]*si.RejectedApplication, 0)

	for _, app := range request.New {  // what is request.New
        ...
	if err = partition.AddApplication(schedApp); err != nil {
		...
	}
	...
}
```

### 了解 ```request``` 的資料結構
```rmevent.RMUpdateApplicationEvent```:
```go
// Incoming UpdateApplication events from the RM to the scheduler (async)
type RMUpdateApplicationEvent struct {
	// The generic UpdateApplication does not wait for a result,
	// results are communicated back via the outgoing events.
	Request *si.ApplicationRequest
}
```

```si.ApplicationRequest```:
```go
type ApplicationRequest struct {
	// RM should explicitly add application when allocation request also explictly belongs to application.
	// This is optional if allocation request doesn't belong to a application. (Independent allocation)
	New []*AddApplicationRequest `protobuf:"bytes,1,rep,name=new,proto3" json:"new,omitempty"`  // this is the event.Request 
	// RM can also remove applications, all allocation/allocation requests associated with the application will be removed
	Remove []*RemoveApplicationRequest `protobuf:"bytes,2,rep,name=remove,proto3" json:"remove,omitempty"`
	// ID of RM, this will be used to identify which RM of the request comes from.
	RmID                 string   `protobuf:"bytes,3,opt,name=rmID,proto3" json:"rmID,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}
```

```AddApplicationRequest```:
```go
type AddApplicationRequest struct {
	// The ID of the application, must be unique
	ApplicationID string `protobuf:"bytes,1,opt,name=applicationID,proto3" json:"applicationID,omitempty"`
	// The queue this application is requesting. The scheduler will place the application into a
	// queue according to policy, taking into account the requested queue as per the policy.
	QueueName string `protobuf:"bytes,2,opt,name=queueName,proto3" json:"queueName,omitempty"`
	// The partition the application belongs to
	PartitionName string `protobuf:"bytes,3,opt,name=partitionName,proto3" json:"partitionName,omitempty"`
	// The user group information of the application owner
	Ugi *UserGroupInformation `protobuf:"bytes,4,opt,name=ugi,proto3" json:"ugi,omitempty"`
	// A set of tags for the application. These tags provide application level generic inforamtion.
	// The tags are optional and are used in placing an appliction or scheduling.
	// Application tags are not considered when processing AllocationAsks.
	Tags map[string]string `protobuf:"bytes,5,rep,name=tags,proto3" json:"tags,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	// Execution timeout: How long this application can be in a running state
	// 0 or negative value means never expire.
	ExecutionTimeoutMilliSeconds int64 `protobuf:"varint,6,opt,name=executionTimeoutMilliSeconds,proto3" json:"executionTimeoutMilliSeconds,omitempty"`
	// The total amount of resources gang placeholders will request
	PlaceholderAsk *Resource `protobuf:"bytes,7,opt,name=placeholderAsk,proto3" json:"placeholderAsk,omitempty"`
	// Gang scheduling style can be hard (the application will fail after placeholder timeout)
	// or soft (after the timeout the application will be scheduled as a normal application)
	GangSchedulingStyle  string   `protobuf:"bytes,8,opt,name=gangSchedulingStyle,proto3" json:"gangSchedulingStyle,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}
```
* in log:
```
&
{
    Request: 
        new: < 
            applicationID: "nginx_2019_01_22_00001"
            queueName: "root.sandbox"
            partitionName: "[mycluster]default"
            ugi: < user: "nobody" > 
            tags: < key: "namespace" value: "yunikorn" > 
            tags: < key: "yunikorn.apache.org/schedulingPolicyParameters" value: "" > 
            tags: < key: "yunikorn.apache.org/task-groups" value: "" > 
            gangSchedulingStyle: "Soft" 
        > 
        rmID: "mycluster"
}
```

### 往下追 ```handleRMUpdateApplicationEvent``` 的判斷過程
https://github.com/apache/yunikorn-core/blob/a590b7d0059cc875bc9ba5c81451a3db14c54326/pkg/scheduler/context.go#L484
```go
func (cc *ClusterContext) handleRMUpdateApplicationEvent(event *rmevent.RMUpdateApplicationEvent) {
	request := event.Request
	if len(request.New) == 0 && len(request.Remove) == 0 {
		return
	}
	acceptedApps := make([]*si.AcceptedApplication, 0)
	rejectedApps := make([]*si.RejectedApplication, 0)

	for _, app := range request.New {  // what is request.New
        ...
	if err = partition.AddApplication(schedApp); err != nil {
		...
	}
	...
}
```

```AddApplication()```  
https://github.com/apache/yunikorn-core/blob/a590b7d0059cc875bc9ba5c81451a3db14c54326/pkg/scheduler/partition.go#L307
```go
func (pc *PartitionContext) AddApplication(app *objects.Application) error {
	...
	
	// Put app under the queue
	queueName := app.GetQueuePath()
	pm := pc.getPlacementManager()
	if pm.IsInitialised() {
		err := pm.PlaceApplication(app)
		if err != nil {
			return fmt.Errorf("failed to place application %s: %v", appID, err)
		}
		queueName = app.GetQueuePath()
		if queueName == "" {
			return fmt.Errorf("application rejected by placement rules: %s", appID)
		}
	}
	// lock the partition and make the last change: we need to do this before creating the queues.
	// queue cleanup might otherwise remove the queue again before we can add the application
	
	...

	return nil
}
```

```PlaceApplication```  
https://github.com/apache/yunikorn-core/blob/a590b7d0059cc875bc9ba5c81451a3db14c54326/pkg/scheduler/placement/placement.go#L135
```go
func (m *AppPlacementManager) PlaceApplication(app *objects.Application) error {
	// Placement manager not initialised cannot place application, just return
	m.RLock()
	defer m.RUnlock()
	if !m.initialised {
		return nil
	}
	var queueName string
	var err error
	for _, checkRule := range m.rules {  // 想先找到 rules 有哪些東西
		log.Logger().Debug("Executing rule for placing application",
			zap.String("ruleName", checkRule.getName()),
			zap.String("application", app.ApplicationID))
		queueName, err = checkRule.placeApplication(app, m.queueFn)
		if err != nil {
			log.Logger().Error("rule execution failed",
				zap.String("ruleName", checkRule.getName()),
				zap.Error(err))
			app.SetQueuePath("")
			return err
		}
		// queueName returned make sure ACL allows access and create the queueName if not exist
		if queueName != "" {
			// get the queue object
			queue := m.queueFn(queueName)
			// walk up the tree if the queue does not exist
			if queue == nil {
				current := queueName
				for queue == nil {
					current = current[0:strings.LastIndex(current, configs.DOT)]
					// check if the queue exist
					queue = m.queueFn(current)
				}
				// Check if the user is allowed to submit to this queueName, if not next rule
				if !queue.CheckSubmitAccess(app.GetUser()) {
					log.Logger().Debug("Submit access denied on queue",
						zap.String("queueName", queue.GetQueuePath()),
						zap.String("ruleName", checkRule.getName()),
						zap.String("application", app.ApplicationID))
					// reset the queue name for the last rule in the chain
					queueName = ""
					continue
				}
			} else {
				// Check if this final queue is a leaf queue, if not next rule
				if !queue.IsLeafQueue() {
					log.Logger().Debug("Rule returned parent queue",
						zap.String("queueName", queueName),
						zap.String("ruleName", checkRule.getName()),
						zap.String("application", app.ApplicationID))
					// reset the queue name for the last rule in the chain
					queueName = ""
					continue
				}
				// Check if the user is allowed to submit to this queueName, if not next rule
				if !queue.CheckSubmitAccess(app.GetUser()) {
					log.Logger().Debug("Submit access denied on queue",
						zap.String("queueName", queueName),
						zap.String("ruleName", checkRule.getName()),
						zap.String("application", app.ApplicationID))
					// reset the queue name for the last rule in the chain
					queueName = ""
					continue
				}
			}
			// we have a queue that allows submitting and can be created: app placed
			break
		}
	}
	log.Logger().Debug("Rule result for placing application",
		zap.String("application", app.ApplicationID),
		zap.String("queueName", queueName))
	// no more rules to check no queueName found reject placement
	if queueName == "" {
		app.SetQueuePath("")
		return fmt.Errorf("application rejected: no placement rule matched")
	}
	// Add the queue into the application, overriding what was submitted
	app.SetQueuePath(queueName)
	return nil
}
```

### deploy 一個資源要求過多的任務，並且從 log 中看看發生什麼事  
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx
  name: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
        applicationId: "nginx_2019_01_22_00001"
        queue: root.sandbox
      annotations:
        yunikorn.apache.org/schedulingPolicyParameters: "gangSchedulingStyle=Hard" # from Soft to Hard
      name: nginx
    spec:
      schedulerName: yunikorn
      containers:
        - name: nginx
          image: "nginx:1.11.1-alpine"
          resources:
            requests:
              cpu: "50000000m"		# change resources requests
              memory: "1024000000M"

```
in log:  
```
2022-05-20T04:58:40.160Z	INFO	cache/context.go:632	app added	{"appID": "nginx_2019_01_22_00001"}
2022-05-20T04:58:40.160Z	INFO	cache/context.go:696	task added	{"appID": "nginx_2019_01_22_00001", "taskID": "d802d262-134d-4248-ad17-63c144bf4c8b", "taskState": "New"}
2022-05-20T04:58:40.835Z	INFO	cache/application.go:461	handle app submission	{"app": "applicationID: nginx_2019_01_22_00001, queue: root.sandbox, partition: default, totalNumOfTasks: 1, currentState: Submitted", "clusterID": "mycluster"}
2022-05-20T04:58:40.835Z	INFO	scheduler/context.go:488	enter handleRMUpdateAllocationEvent()
2022-05-20T04:58:40.835Z	INFO	scheduler/context.go:490	&{Request:new:<applicationID:"nginx_2019_01_22_00001" queueName:"root.sandbox" partitionName:"[mycluster]default" ugi:<user:"nobody" > tags:<key:"namespace" value:"yunikorn" > tags:<key:"yunikorn.apache.org/schedulingPolicyParameters" value:"gangSchedulingStyle=Hard" > tags:<key:"yunikorn.apache.org/task-groups" value:"" > gangSchedulingStyle:"Hard" > rmID:"mycluster" }

2022-05-20T04:58:40.835Z	INFO	placement/tag_rule.go:114	Tag rule application placed	{"application": "nginx_2019_01_22_00001", "queue": "root.yunikorn"}
2022-05-20T04:58:40.836Z	INFO	objects/queue.go:150	dynamic queue added to scheduler	{"queueName": "root.yunikorn"}
2022-05-20T04:58:40.836Z	INFO	scheduler/context.go:548	Added application to partition	{"applicationID": "nginx_2019_01_22_00001", "partitionName": "[mycluster]default", "requested queue": "root.sandbox", "placed queue": "root.yunikorn"}
2022-05-20T04:58:40.836Z	INFO	callback/scheduler_callback.go:114	Accepting app	{"appID": "nginx_2019_01_22_00001"}
2022-05-20T04:58:41.836Z	INFO	cache/application.go:557	Skip the reservation stage	{"appID": "nginx_2019_01_22_00001"}
2022-05-20T04:58:42.837Z	INFO	objects/application_state.go:129	Application state transition	{"appID": "nginx_2019_01_22_00001", "source": "New", "destination": "Accepted", "event": "runApplication"}
2022-05-20T04:58:42.837Z	INFO	objects/application.go:585	Ask added successfully to application	{"appID": "nginx_2019_01_22_00001", "ask": "d802d262-134d-4248-ad17-63c144bf4c8b", "placeholder": false, "pendingDelta": "map[memory:1024000000000000 vcore:50000000]"}
```
compare to old version:
```
# shim 接收到了 nginx 的 request
2022-05-12T11:18:45.440Z	INFO	cache/context.go:632	app added	{"appID": "nginx_2019_01_22_00001"}
2022-05-12T11:18:45.440Z	INFO	cache/context.go:696	task added	{"appID": "nginx_2019_01_22_00001", "taskID": "ddb3c4f7-d6e0-422c-8fda-7ae9e3c6c4c7", "taskState": "New"}
2022-05-12T11:18:45.992Z	INFO	cache/application.go:461	handle app submission	{"app": "applicationID: nginx_2019_01_22_00001, queue: root.sandbox, partition: default, totalNumOfTasks: 1, currentState: Submitted", "clusterID": "mycluster"}

# 我自己加上的兩行 log, core 開始處理 request
2022-05-12T11:18:45.992Z	INFO	scheduler/context.go:488	enter handleRMUpdateAllocationEvent()
2022-05-12T11:18:45.993Z	INFO	scheduler/context.go:490	&{Request:new:<applicationID:"nginx_2019_01_22_00001" queueName:"root.sandbox" partitionName:"[mycluster]default" ugi:<user:"nobody" > tags:<key:"namespace" value:"yunikorn" > tags:<key:"yunikorn.apache.org/schedulingPolicyParameters" value:"" > tags:<key:"yunikorn.apache.org/task-groups" value:"" > gangSchedulingStyle:"Soft" > rmID:"mycluster" }

2022-05-12T11:18:45.993Z	INFO	placement/tag_rule.go:114	Tag rule application placed	{"application": "nginx_2019_01_22_00001", "queue": "root.yunikorn"}
2022-05-12T11:18:45.993Z	INFO	objects/queue.go:150	dynamic queue added to scheduler	{"queueName": "root.yunikorn"}
# 把 nginx 加入 partition
2022-05-12T11:18:45.993Z	INFO	scheduler/context.go:548	Added application to partition	{"applicationID": "nginx_2019_01_22_00001", "partitionName": "[mycluster]default", "requested queue": "root.sandbox", "placed queue": "root.yunikorn"}

# 回到 shim 處理
2022-05-12T11:18:45.993Z	INFO	callback/scheduler_callback.go:114	Accepting app	{"appID": "nginx_2019_01_22_00001"}
2022-05-12T11:18:46.993Z	INFO	cache/application.go:557	Skip the reservation stage	{"appID": "nginx_2019_01_22_00001"}
2022-05-12T11:18:47.994Z	INFO	objects/application_state.go:129	Application state transition	{"appID": "nginx_2019_01_22_00001", "source": "New", "destination": "Accepted", "event": "runApplication"}
2022-05-12T11:18:47.994Z	INFO	objects/application.go:585	Ask added successfully to application	{"appID": "nginx_2019_01_22_00001", "ask": "ddb3c4f7-d6e0-422c-8fda-7ae9e3c6c4c7", "placeholder": false, "pendingDelta": "map[memory:1024000000 vcore:500]"}

### *這行底下是原本的版本才有的
2022-05-12T11:18:47.994Z	INFO	objects/application_state.go:129	Application state transition	{"appID": "nginx_2019_01_22_00001", "source": "Accepted", "destination": "Starting", "event": "runApplication"}
2022-05-12T11:18:47.994Z	INFO	scheduler/partition.go:923	scheduler allocation processed	{"appID": "nginx_2019_01_22_00001", "allocationKey": "ddb3c4f7-d6e0-422c-8fda-7ae9e3c6c4c7", "UUID": "90bb0f6b-8c60-48f8-af38-6451cd736c99", "allocatedResource": "map[memory:1024000000 vcore:500]", "placeholder": false, "targetNode": "lab5"}
2022-05-12T11:18:47.994Z	INFO	cache/context.go:359	Binding Pod Volumes skipped: all volumes already bound	{"podName": "nginx-7b4896995-tvt9t"}

# shim 通過 api 通知 kubernetes
2022-05-12T11:18:47.994Z	INFO	client/kubeclient.go:84	bind pod to node	{"podName": "nginx-7b4896995-tvt9t", "podUID": "ddb3c4f7-d6e0-422c-8fda-7ae9e3c6c4c7", "nodeID": "lab5"}
2022-05-12T11:18:47.999Z	INFO	cache/task.go:418	successfully bound pod	{"podName": "nginx-7b4896995-tvt9t"}
2022-05-12T11:20:02.973Z	INFO	configs/configwatcher.go:143	config watcher timed out
2022-05-12T11:22:02.973Z	INFO	shim/scheduler.go:356	No outstanding apps found for a while	{"timeout": "2m0s"}
2022-05-12T11:23:47.994Z	INFO	objects/application_state.go:129	Application state transition	{"appID": "nginx_2019_01_22_00001", "source": "Starting", "destination": "Running", "event": "runApplication"}
```
